{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gn3SG1yo1KdV"
   },
   "source": [
    "<div>\n",
    "<img src=https://www.institutedata.com/wp-content/uploads/2019/10/iod_h_tp_primary_c.svg width=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g-SD7a9X1KdY"
   },
   "source": [
    "# Lab 10.1: NN with Keras\n",
    "INSTRUCTIONS:\n",
    "- Read the guides and hints, then create the necessary analysis and code to find an answer and conclusion for the task below.\n",
    "- **NOTE**: This is a Regression problem. Consider the appropriate:\n",
    "    - Activation function\n",
    "    - Loss/Cost Function\n",
    "    - Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ENgfRnvL1Kdc"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z9H465X-1Kde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0-rc0\n",
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "# insert code here\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5FHh910J1Kdm"
   },
   "source": [
    "### Load data\n",
    "Load the Diabetes dataset from **SciKit-Learn**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MWu8SlQF1Kdo"
   },
   "outputs": [],
   "source": [
    "# insert code here\n",
    "diabetes = load_diabetes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xR_yLpR01Kdr"
   },
   "source": [
    "### Prepare input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sp2mf2bB1Kds",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.03807591,  0.05068012,  0.06169621, ..., -0.00259226,\n",
       "          0.01990842, -0.01764613],\n",
       "        [-0.00188202, -0.04464164, -0.05147406, ..., -0.03949338,\n",
       "         -0.06832974, -0.09220405],\n",
       "        [ 0.08529891,  0.05068012,  0.04445121, ..., -0.00259226,\n",
       "          0.00286377, -0.02593034],\n",
       "        ...,\n",
       "        [ 0.04170844,  0.05068012, -0.01590626, ..., -0.01107952,\n",
       "         -0.04687948,  0.01549073],\n",
       "        [-0.04547248, -0.04464164,  0.03906215, ...,  0.02655962,\n",
       "          0.04452837, -0.02593034],\n",
       "        [-0.04547248, -0.04464164, -0.0730303 , ..., -0.03949338,\n",
       "         -0.00421986,  0.00306441]]),\n",
       " 'target': array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
       "         69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
       "         68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
       "         87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
       "        259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
       "        128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
       "        150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
       "        200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
       "         42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
       "         83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
       "        104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
       "        173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
       "        107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
       "         60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
       "        197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
       "         59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
       "        237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
       "        143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
       "        142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
       "         77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
       "         78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
       "        154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
       "         71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
       "        150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
       "        145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
       "         94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
       "         60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
       "         31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
       "        114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
       "        191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
       "        244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
       "        263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
       "         77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
       "         58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
       "        140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
       "        219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
       "         43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
       "        140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
       "         84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
       "         94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
       "        220.,  57.]),\n",
       " 'frame': None,\n",
       " 'DESCR': '.. _diabetes_dataset:\\n\\nDiabetes dataset\\n----------------\\n\\nTen baseline variables, age, sex, body mass index, average blood\\npressure, and six blood serum measurements were obtained for each of n =\\n442 diabetes patients, as well as the response of interest, a\\nquantitative measure of disease progression one year after baseline.\\n\\n**Data Set Characteristics:**\\n\\n  :Number of Instances: 442\\n\\n  :Number of Attributes: First 10 columns are numeric predictive values\\n\\n  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\\n\\n  :Attribute Information:\\n      - age     age in years\\n      - sex\\n      - bmi     body mass index\\n      - bp      average blood pressure\\n      - s1      tc, T-Cells (a type of white blood cells)\\n      - s2      ldl, low-density lipoproteins\\n      - s3      hdl, high-density lipoproteins\\n      - s4      tch, thyroid stimulating hormone\\n      - s5      ltg, lamotrigine\\n      - s6      glu, blood sugar level\\n\\nNote: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\\n\\nSource URL:\\nhttps://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\\n\\nFor more information see:\\nBradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\\n(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)',\n",
       " 'feature_names': ['age',\n",
       "  'sex',\n",
       "  'bmi',\n",
       "  'bp',\n",
       "  's1',\n",
       "  's2',\n",
       "  's3',\n",
       "  's4',\n",
       "  's5',\n",
       "  's6'],\n",
       " 'data_filename': '/Users/jinyang/miniforge3/envs/opencv/lib/python3.8/site-packages/sklearn/datasets/data/diabetes_data.csv.gz',\n",
       " 'target_filename': '/Users/jinyang/miniforge3/envs/opencv/lib/python3.8/site-packages/sklearn/datasets/data/diabetes_target.csv.gz'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# insert code here\n",
    "diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "X = diabetes.data\n",
    "print(type(X))\n",
    "n_cols = X.shape[1]\n",
    "y = diabetes.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>442.0</td>\n",
       "      <td>-3.639623e-16</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>-0.107226</td>\n",
       "      <td>-0.037299</td>\n",
       "      <td>0.005383</td>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.110727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>442.0</td>\n",
       "      <td>1.309912e-16</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.050680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>442.0</td>\n",
       "      <td>-8.013951e-16</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>-0.090275</td>\n",
       "      <td>-0.034229</td>\n",
       "      <td>-0.007284</td>\n",
       "      <td>0.031248</td>\n",
       "      <td>0.170555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>442.0</td>\n",
       "      <td>1.289818e-16</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>-0.112400</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>0.035644</td>\n",
       "      <td>0.132044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>442.0</td>\n",
       "      <td>-9.042540e-17</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>-0.126781</td>\n",
       "      <td>-0.034248</td>\n",
       "      <td>-0.004321</td>\n",
       "      <td>0.028358</td>\n",
       "      <td>0.153914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>442.0</td>\n",
       "      <td>1.301121e-16</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>-0.115613</td>\n",
       "      <td>-0.030358</td>\n",
       "      <td>-0.003819</td>\n",
       "      <td>0.029844</td>\n",
       "      <td>0.198788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>442.0</td>\n",
       "      <td>-4.563971e-16</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>-0.102307</td>\n",
       "      <td>-0.035117</td>\n",
       "      <td>-0.006584</td>\n",
       "      <td>0.029312</td>\n",
       "      <td>0.181179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>442.0</td>\n",
       "      <td>3.863174e-16</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>-0.076395</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.185234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>442.0</td>\n",
       "      <td>-3.848103e-16</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>-0.126097</td>\n",
       "      <td>-0.033249</td>\n",
       "      <td>-0.001948</td>\n",
       "      <td>0.032433</td>\n",
       "      <td>0.133599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>442.0</td>\n",
       "      <td>-3.398488e-16</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>-0.137767</td>\n",
       "      <td>-0.033179</td>\n",
       "      <td>-0.001078</td>\n",
       "      <td>0.027917</td>\n",
       "      <td>0.135612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count          mean       std       min       25%       50%       75%  \\\n",
       "0  442.0 -3.639623e-16  0.047619 -0.107226 -0.037299  0.005383  0.038076   \n",
       "1  442.0  1.309912e-16  0.047619 -0.044642 -0.044642 -0.044642  0.050680   \n",
       "2  442.0 -8.013951e-16  0.047619 -0.090275 -0.034229 -0.007284  0.031248   \n",
       "3  442.0  1.289818e-16  0.047619 -0.112400 -0.036656 -0.005671  0.035644   \n",
       "4  442.0 -9.042540e-17  0.047619 -0.126781 -0.034248 -0.004321  0.028358   \n",
       "5  442.0  1.301121e-16  0.047619 -0.115613 -0.030358 -0.003819  0.029844   \n",
       "6  442.0 -4.563971e-16  0.047619 -0.102307 -0.035117 -0.006584  0.029312   \n",
       "7  442.0  3.863174e-16  0.047619 -0.076395 -0.039493 -0.002592  0.034309   \n",
       "8  442.0 -3.848103e-16  0.047619 -0.126097 -0.033249 -0.001948  0.032433   \n",
       "9  442.0 -3.398488e-16  0.047619 -0.137767 -0.033179 -0.001078  0.027917   \n",
       "\n",
       "        max  \n",
       "0  0.110727  \n",
       "1  0.050680  \n",
       "2  0.170555  \n",
       "3  0.132044  \n",
       "4  0.153914  \n",
       "5  0.198788  \n",
       "6  0.181179  \n",
       "7  0.185234  \n",
       "8  0.133599  \n",
       "9  0.135612  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X).describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
       "        69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
       "        68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
       "        87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
       "       259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
       "       128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
       "       150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
       "       200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
       "        42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
       "        83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
       "       104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
       "       173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
       "       107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
       "        60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
       "       197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
       "        59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
       "       237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
       "       143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
       "       142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
       "        77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
       "        78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
       "       154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
       "        71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
       "       150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
       "       145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
       "        94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
       "        60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
       "        31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
       "       114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
       "       191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
       "       244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
       "       263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
       "        77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
       "        58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
       "       140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
       "       219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
       "        43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
       "       140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
       "        84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
       "        94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
       "       220.,  57.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j1Vsh6cm1Kdv"
   },
   "source": [
    "### Split the data (training/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O341llJz1Kdw"
   },
   "outputs": [],
   "source": [
    "# insert code here\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o4dJViJD1Kd0"
   },
   "source": [
    "### Create the model's architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 10)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_cols = X.shape[1]\n",
    "n_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tkgf_BLl1Kd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_33 (Dense)             (None, 15)                165       \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 8)                 128       \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 302\n",
      "Trainable params: 302\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# insert code here\n",
    "model = Sequential()\n",
    "model.add(Dense(15, input_shape=(10,), activation = 'relu'))\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'linear'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5hQTS42V1Kd4"
   },
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BvLsoanF1Kd5"
   },
   "outputs": [],
   "source": [
    "# insert code here\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6KPQbnEj1Kd7"
   },
   "source": [
    "### Fit the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-oiuHjEj1Kd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 31000.7102 - accuracy: 0.0000e+00 - val_loss: 33183.1016 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 28119.6783 - accuracy: 0.0000e+00 - val_loss: 33099.7461 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 27430.4127 - accuracy: 0.0000e+00 - val_loss: 32969.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 30297.8056 - accuracy: 0.0000e+00 - val_loss: 32778.2031 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 27890.4541 - accuracy: 0.0000e+00 - val_loss: 32509.1738 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 27388.7927 - accuracy: 0.0000e+00 - val_loss: 32139.9766 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 27975.9217 - accuracy: 0.0000e+00 - val_loss: 31653.0020 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 26483.2023 - accuracy: 0.0000e+00 - val_loss: 31039.3008 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 29145.3805 - accuracy: 0.0000e+00 - val_loss: 30275.6035 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 25816.0527 - accuracy: 0.0000e+00 - val_loss: 29386.2344 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 27241.6556 - accuracy: 0.0000e+00 - val_loss: 28337.2344 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 25413.8936 - accuracy: 0.0000e+00 - val_loss: 27176.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 24013.8519 - accuracy: 0.0000e+00 - val_loss: 25831.8125 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 21599.0716 - accuracy: 0.0000e+00 - val_loss: 24406.6543 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 21579.2997 - accuracy: 0.0000e+00 - val_loss: 22855.9590 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 19059.9161 - accuracy: 0.0000e+00 - val_loss: 21262.1230 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 15687.5749 - accuracy: 0.0000e+00 - val_loss: 19596.8379 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 15674.8621 - accuracy: 0.0000e+00 - val_loss: 17889.2715 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 13640.5388 - accuracy: 0.0000e+00 - val_loss: 16253.5176 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 12349.5354 - accuracy: 0.0000e+00 - val_loss: 14602.2734 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 10681.0378 - accuracy: 0.0000e+00 - val_loss: 13044.9473 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 9290.5453 - accuracy: 0.0000e+00 - val_loss: 11592.5488 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 9017.5115 - accuracy: 0.0000e+00 - val_loss: 10297.9004 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 8704.3587 - accuracy: 0.0000e+00 - val_loss: 9156.2090 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 7238.8330 - accuracy: 0.0000e+00 - val_loss: 8187.7744 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 5416.6663 - accuracy: 0.0000e+00 - val_loss: 7373.0728 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 6621.2548 - accuracy: 0.0000e+00 - val_loss: 6695.0825 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 6123.8807 - accuracy: 0.0000e+00 - val_loss: 6132.4165 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 5199.4453 - accuracy: 0.0000e+00 - val_loss: 5741.0640 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 4815.1779 - accuracy: 0.0000e+00 - val_loss: 5403.1543 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 4755.9372 - accuracy: 0.0000e+00 - val_loss: 5162.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 4268.3200 - accuracy: 0.0000e+00 - val_loss: 4995.7310 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 4167.3091 - accuracy: 0.0000e+00 - val_loss: 4803.9458 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 4193.5225 - accuracy: 0.0000e+00 - val_loss: 4695.9600 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 4161.8573 - accuracy: 0.0000e+00 - val_loss: 4594.6904 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 4546.2713 - accuracy: 0.0000e+00 - val_loss: 4510.4062 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 4600.6721 - accuracy: 0.0000e+00 - val_loss: 4436.8345 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 4043.4297 - accuracy: 0.0000e+00 - val_loss: 4378.9941 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3947.2987 - accuracy: 0.0000e+00 - val_loss: 4305.2544 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3801.4332 - accuracy: 0.0000e+00 - val_loss: 4284.8086 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 4211.1146 - accuracy: 0.0000e+00 - val_loss: 4237.2974 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 4043.2023 - accuracy: 0.0000e+00 - val_loss: 4191.4395 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 4435.2817 - accuracy: 0.0000e+00 - val_loss: 4143.4731 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3878.0127 - accuracy: 0.0000e+00 - val_loss: 4117.9976 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3992.4719 - accuracy: 0.0000e+00 - val_loss: 4100.1577 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3884.0514 - accuracy: 0.0000e+00 - val_loss: 4051.0986 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3719.9994 - accuracy: 0.0000e+00 - val_loss: 4026.1663 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3865.7186 - accuracy: 0.0000e+00 - val_loss: 3971.2563 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3723.1771 - accuracy: 0.0000e+00 - val_loss: 3966.7737 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3842.4720 - accuracy: 0.0000e+00 - val_loss: 3932.5901 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3538.3734 - accuracy: 0.0000e+00 - val_loss: 3906.9324 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3630.1151 - accuracy: 0.0000e+00 - val_loss: 3873.7583 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 1ms/step - loss: 3747.7285 - accuracy: 0.0000e+00 - val_loss: 3840.1162 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3968.0628 - accuracy: 0.0000e+00 - val_loss: 3822.3140 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3941.3913 - accuracy: 0.0000e+00 - val_loss: 3823.9768 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3553.4492 - accuracy: 0.0000e+00 - val_loss: 3796.3953 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3276.4551 - accuracy: 0.0000e+00 - val_loss: 3775.2751 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3456.9240 - accuracy: 0.0000e+00 - val_loss: 3746.5222 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3302.0066 - accuracy: 0.0000e+00 - val_loss: 3742.3638 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3576.2982 - accuracy: 0.0000e+00 - val_loss: 3696.6165 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3343.1532 - accuracy: 0.0000e+00 - val_loss: 3697.6333 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3437.8747 - accuracy: 0.0000e+00 - val_loss: 3678.5688 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3488.3084 - accuracy: 0.0000e+00 - val_loss: 3643.3101 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3413.7885 - accuracy: 0.0000e+00 - val_loss: 3639.7476 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3702.6340 - accuracy: 0.0000e+00 - val_loss: 3616.8984 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3758.0297 - accuracy: 0.0000e+00 - val_loss: 3620.5474 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3411.8414 - accuracy: 0.0000e+00 - val_loss: 3601.3257 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3280.5828 - accuracy: 0.0000e+00 - val_loss: 3568.8193 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3430.6644 - accuracy: 0.0000e+00 - val_loss: 3574.1072 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3338.0904 - accuracy: 0.0000e+00 - val_loss: 3548.3669 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3302.5113 - accuracy: 0.0000e+00 - val_loss: 3550.5071 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3444.5292 - accuracy: 0.0000e+00 - val_loss: 3528.1443 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3312.2521 - accuracy: 0.0000e+00 - val_loss: 3517.1650 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3423.3534 - accuracy: 0.0000e+00 - val_loss: 3486.8584 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3179.5387 - accuracy: 0.0000e+00 - val_loss: 3492.3145 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3395.6329 - accuracy: 0.0000e+00 - val_loss: 3503.4172 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3562.6924 - accuracy: 0.0000e+00 - val_loss: 3476.5483 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3317.1199 - accuracy: 0.0000e+00 - val_loss: 3458.3706 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3065.9715 - accuracy: 0.0000e+00 - val_loss: 3472.3083 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3234.3187 - accuracy: 0.0000e+00 - val_loss: 3433.7065 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3035.8271 - accuracy: 0.0000e+00 - val_loss: 3425.1902 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3438.3159 - accuracy: 0.0000e+00 - val_loss: 3435.8113 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3263.0646 - accuracy: 0.0000e+00 - val_loss: 3415.4470 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3130.2694 - accuracy: 0.0000e+00 - val_loss: 3419.9912 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3090.1444 - accuracy: 0.0000e+00 - val_loss: 3393.6343 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3183.2913 - accuracy: 0.0000e+00 - val_loss: 3406.0608 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3286.3501 - accuracy: 0.0000e+00 - val_loss: 3400.0452 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3111.5837 - accuracy: 0.0000e+00 - val_loss: 3372.0398 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3265.0115 - accuracy: 0.0000e+00 - val_loss: 3362.2236 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3009.1199 - accuracy: 0.0000e+00 - val_loss: 3355.1450 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 2972.0163 - accuracy: 0.0000e+00 - val_loss: 3374.1936 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3198.1906 - accuracy: 0.0000e+00 - val_loss: 3343.9111 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/150\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 2909.1659 - accuracy: 0.0000e+00 - val_loss: 3363.7185 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3083.1521 - accuracy: 0.0000e+00 - val_loss: 3347.6338 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3065.7964 - accuracy: 0.0000e+00 - val_loss: 3314.6355 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 2888.5125 - accuracy: 0.0000e+00 - val_loss: 3337.6887 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3230.4181 - accuracy: 0.0000e+00 - val_loss: 3333.6184 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3018.3359 - accuracy: 0.0000e+00 - val_loss: 3321.1624 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3095.1122 - accuracy: 0.0000e+00 - val_loss: 3318.8645 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 2867.7085 - accuracy: 0.0000e+00 - val_loss: 3303.3896 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3024.7989 - accuracy: 0.0000e+00 - val_loss: 3309.1870 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3222.6848 - accuracy: 0.0000e+00 - val_loss: 3292.1814 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3123.8583 - accuracy: 0.0000e+00 - val_loss: 3322.2668 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3024.0796 - accuracy: 0.0000e+00 - val_loss: 3305.9072 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 1ms/step - loss: 3122.1115 - accuracy: 0.0000e+00 - val_loss: 3286.7300 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3022.6800 - accuracy: 0.0000e+00 - val_loss: 3284.8784 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 2768.5988 - accuracy: 0.0000e+00 - val_loss: 3272.5005 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3023.8363 - accuracy: 0.0000e+00 - val_loss: 3290.8914 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3177.4600 - accuracy: 0.0000e+00 - val_loss: 3286.1646 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3258.7220 - accuracy: 0.0000e+00 - val_loss: 3299.4077 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 2904.4360 - accuracy: 0.0000e+00 - val_loss: 3263.4438 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3111.0037 - accuracy: 0.0000e+00 - val_loss: 3278.1431 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3148.4171 - accuracy: 0.0000e+00 - val_loss: 3280.0044 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3524.8941 - accuracy: 0.0000e+00 - val_loss: 3267.7224 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3410.2238 - accuracy: 0.0000e+00 - val_loss: 3255.5830 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 2819.0726 - accuracy: 0.0000e+00 - val_loss: 3255.6428 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3290.0009 - accuracy: 0.0000e+00 - val_loss: 3278.1274 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3128.0040 - accuracy: 0.0000e+00 - val_loss: 3256.6233 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3020.4732 - accuracy: 0.0000e+00 - val_loss: 3282.8020 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3023.7057 - accuracy: 0.0000e+00 - val_loss: 3223.9937 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 2920.9410 - accuracy: 0.0000e+00 - val_loss: 3243.7249 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3224.8685 - accuracy: 0.0000e+00 - val_loss: 3249.4456 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3211.3188 - accuracy: 0.0000e+00 - val_loss: 3220.4360 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3125.4059 - accuracy: 0.0000e+00 - val_loss: 3235.3892 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 2739.0454 - accuracy: 0.0000e+00 - val_loss: 3239.3171 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 2819.6462 - accuracy: 0.0000e+00 - val_loss: 3261.9553 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3222.2468 - accuracy: 0.0000e+00 - val_loss: 3238.1265 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 2790.2589 - accuracy: 0.0000e+00 - val_loss: 3218.7549 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3068.4620 - accuracy: 0.0000e+00 - val_loss: 3245.2593 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 2911.7284 - accuracy: 0.0000e+00 - val_loss: 3227.3311 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 2787.9270 - accuracy: 0.0000e+00 - val_loss: 3217.8525 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3157.8833 - accuracy: 0.0000e+00 - val_loss: 3192.1355 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3176.3174 - accuracy: 0.0000e+00 - val_loss: 3217.6052 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 2765.2844 - accuracy: 0.0000e+00 - val_loss: 3206.6091 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 2948.4641 - accuracy: 0.0000e+00 - val_loss: 3237.3384 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3144.7324 - accuracy: 0.0000e+00 - val_loss: 3225.6145 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 2650.9726 - accuracy: 0.0000e+00 - val_loss: 3227.1543 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3103.4307 - accuracy: 0.0000e+00 - val_loss: 3215.8115 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 2993.1106 - accuracy: 0.0000e+00 - val_loss: 3232.4641 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 2703.9925 - accuracy: 0.0000e+00 - val_loss: 3204.8916 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 2964.9269 - accuracy: 0.0000e+00 - val_loss: 3201.4971 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3078.1185 - accuracy: 0.0000e+00 - val_loss: 3216.7896 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 2938.4936 - accuracy: 0.0000e+00 - val_loss: 3215.8982 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 2750.3841 - accuracy: 0.0000e+00 - val_loss: 3241.9697 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 2985.9771 - accuracy: 0.0000e+00 - val_loss: 3205.7263 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 2918.0765 - accuracy: 0.0000e+00 - val_loss: 3213.7310 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 2940.9591 - accuracy: 0.0000e+00 - val_loss: 3193.1841 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 2851.9691 - accuracy: 0.0000e+00 - val_loss: 3185.5833 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 2754.9231 - accuracy: 0.0000e+00 - val_loss: 3208.1624 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 2886.4279 - accuracy: 0.0000e+00 - val_loss: 3201.0032 - val_accuracy: 0.0000e+00\n",
      "CPU times: user 5.23 s, sys: 510 ms, total: 5.74 s\n",
      "Wall time: 5.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# insert code here\n",
    "history = model.fit(X_train, y_train, epochs=150, \n",
    "                    batch_size=10, verbose=1, \n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CR-kCu3c1Kd-"
   },
   "source": [
    "### Create predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wkywKqPg1Kd-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# insert code here\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-unEmrGo1KeA"
   },
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QCIVpVrG1KeB",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "If no scoring is specified, the estimator passed should have a 'score' method. The estimator <tensorflow.python.keras.engine.sequential.Sequential object at 0x169a5e7f0> does not.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-907d0cedb0d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# insert code here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mkfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/opencv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/opencv/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \"\"\"\n\u001b[1;32m    437\u001b[0m     \u001b[0;31m# To ensure multimetric format is not supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n",
      "\u001b[0;32m~/miniforge3/envs/opencv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/opencv/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36mcheck_scoring\u001b[0;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m             raise TypeError(\n\u001b[0m\u001b[1;32m    451\u001b[0m                 \u001b[0;34m\"If no scoring is specified, the estimator passed should \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m                 \u001b[0;34m\"have a 'score' method. The estimator %r does not.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: If no scoring is specified, the estimator passed should have a 'score' method. The estimator <tensorflow.python.keras.engine.sequential.Sequential object at 0x169a5e7f0> does not."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# insert code here\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "results = cross_val_score(model, X, y, cv=kfold)\n",
    "print(results.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sSlqjs7e1KeD"
   },
   "source": [
    "### Visualisation of cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1F6hYpNh1KeE",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vQLzMZTM1KeG"
   },
   "source": [
    "### Visualisation of residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "opIulVSw1KeH"
   },
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RERADKgNFq9T"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "> > > > > > > > >  2021 Institute of Data\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DSIA Lab-10_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
